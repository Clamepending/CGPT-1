{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import CGPT_utils\n",
    "\n",
    "t = CGPT_utils.build_transformer(256, 128, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================================================\n",
      "Layer (type:depth-idx)                             Param #\n",
      "===========================================================================\n",
      "├─Encoder: 1-1                                     --\n",
      "|    └─ModuleList: 2-1                             --\n",
      "|    |    └─EncoderBlock: 3-1                      3,150,340\n",
      "|    |    └─EncoderBlock: 3-2                      3,150,340\n",
      "|    |    └─EncoderBlock: 3-3                      3,150,340\n",
      "|    |    └─EncoderBlock: 3-4                      3,150,340\n",
      "|    |    └─EncoderBlock: 3-5                      3,150,340\n",
      "|    |    └─EncoderBlock: 3-6                      3,150,340\n",
      "|    └─LayerNormalization: 2-2                     2\n",
      "├─Decoder: 1-2                                     --\n",
      "|    └─ModuleList: 2-3                             --\n",
      "|    |    └─DecoderBlock: 3-7                      4,200,966\n",
      "|    └─LayerNormalization: 2-4                     2\n",
      "├─InputEmbedding: 1-3                              --\n",
      "|    └─Embedding: 2-5                              131,072\n",
      "├─InputEmbedding: 1-4                              --\n",
      "|    └─Embedding: 2-6                              65,536\n",
      "├─PositionalEncoding: 1-5                          --\n",
      "|    └─Dropout: 2-7                                --\n",
      "├─PositionalEncoding: 1-6                          --\n",
      "|    └─Dropout: 2-8                                --\n",
      "├─ProjectionLayer: 1-7                             --\n",
      "|    └─Linear: 2-9                                 65,664\n",
      "===========================================================================\n",
      "Total params: 23,365,282\n",
      "Trainable params: 23,365,282\n",
      "Non-trainable params: 0\n",
      "===========================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===========================================================================\n",
       "Layer (type:depth-idx)                             Param #\n",
       "===========================================================================\n",
       "├─Encoder: 1-1                                     --\n",
       "|    └─ModuleList: 2-1                             --\n",
       "|    |    └─EncoderBlock: 3-1                      3,150,340\n",
       "|    |    └─EncoderBlock: 3-2                      3,150,340\n",
       "|    |    └─EncoderBlock: 3-3                      3,150,340\n",
       "|    |    └─EncoderBlock: 3-4                      3,150,340\n",
       "|    |    └─EncoderBlock: 3-5                      3,150,340\n",
       "|    |    └─EncoderBlock: 3-6                      3,150,340\n",
       "|    └─LayerNormalization: 2-2                     2\n",
       "├─Decoder: 1-2                                     --\n",
       "|    └─ModuleList: 2-3                             --\n",
       "|    |    └─DecoderBlock: 3-7                      4,200,966\n",
       "|    └─LayerNormalization: 2-4                     2\n",
       "├─InputEmbedding: 1-3                              --\n",
       "|    └─Embedding: 2-5                              131,072\n",
       "├─InputEmbedding: 1-4                              --\n",
       "|    └─Embedding: 2-6                              65,536\n",
       "├─PositionalEncoding: 1-5                          --\n",
       "|    └─Dropout: 2-7                                --\n",
       "├─PositionalEncoding: 1-6                          --\n",
       "|    └─Dropout: 2-8                                --\n",
       "├─ProjectionLayer: 1-7                             --\n",
       "|    └─Linear: 2-9                                 65,664\n",
       "===========================================================================\n",
       "Total params: 23,365,282\n",
       "Trainable params: 23,365,282\n",
       "Non-trainable params: 0\n",
       "==========================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(t, input_size=[(32, 256), (32, 32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BertTokenizer\n\u001b[0;32m      3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m BertTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert-base-cased\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m tokenizer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe cat chased the dog over a fence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "tokenizer(\"The cat chased the dog over a fence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtokenizers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordLevel\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import WordLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d = datasets.load_dataset(name='tiny_shakespeare')['train']\n",
    "d = d.map(lambda x: datasets.Value('strings').unicode_split(x['text'], 'UTF-8'))\n",
    "# train split includes vocabulary for other splits\n",
    "vocabulary = sorted(set(next(iter(d)).numpy()))\n",
    "d = d.map(lambda x: {'cur_char': x[:-1], 'next_char': x[1:]})\n",
    "d = d.unbatch()\n",
    "seq_len = 100\n",
    "batch_size = 2\n",
    "d = d.batch(seq_len)\n",
    "d = d.batch(batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gradio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
